{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f05370",
   "metadata": {},
   "source": [
    "# Neural Network to Classify Hand-Written Digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7e2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcfc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "train_data = data[0:int(0.8*m), :]\n",
    "val_data = data[int(0.8*m):m, :]\n",
    "\n",
    "X_train = train_data[:, 1:].T\n",
    "X_train = X_train / 255.0\n",
    "Y_train = train_data[:, 0]\n",
    "\n",
    "X_val = val_data[:, 1:].T\n",
    "X_val = X_val / 255.0\n",
    "Y_val = val_data[:, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3dd7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "  W1 = np.random.rand(10, 784) - 0.5\n",
    "  B1 = np.random.rand(10, 1) - 0.5\n",
    "  W2 = np.random.rand(10, 10) - 0.5\n",
    "  B2 = np.random.rand(10, 1) - 0.5\n",
    "  return W1, B1, W2, B2\n",
    "\n",
    "def ReLU(X):\n",
    "  return np.maximum(X, 0)\n",
    "\n",
    "def softmax_calculator(Z):\n",
    "  return np.exp(Z) / sum(np.exp(Z))\n",
    "\n",
    "def forward_propagation(W1, B1, W2, B2, X):\n",
    "  Z1 = W1.dot(X) + B1\n",
    "  A1 = ReLU(Z1)\n",
    "  Z2 = W2.dot(A1) + B2\n",
    "  A2 = softmax_calculator(Z2)\n",
    "  return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot_converter(Y):\n",
    "  one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "  one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "  return one_hot_Y.T\n",
    "\n",
    "def backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y):\n",
    "  one_hot_Y = one_hot_converter(Y)\n",
    "  dZ2 = A2 - one_hot_Y\n",
    "  dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "  dB2 = 1 / m * np.sum(dZ2)\n",
    "  dZ1 = W2.T.dot(dZ2) * (Z1 > 0)\n",
    "  dW1 = 1 / m * dZ1.dot(X.T)\n",
    "  dB1 = 1 / m * np.sum(dZ1)\n",
    "  return dW1, dB1, dW2, dB2\n",
    "\n",
    "def update_parameters(W1, B1, W2, B2, dW1, dB1, dW2, dB2, learning_rate):\n",
    "  W1 = W1 - learning_rate * dW1\n",
    "  B1 = B1 - learning_rate * dB1\n",
    "  W2 = W2 - learning_rate * dW2\n",
    "  B2 = B2 - learning_rate * dB2\n",
    "  return W1, B1, W2, B2\n",
    "\n",
    "def get_predictions(A2):\n",
    "  return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "  return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "  W1, B1, W2, B2 = initialize_parameters()\n",
    "\n",
    "  for i in range(iterations):\n",
    "    Z1, A1, Z2, A2 = forward_propagation(W1, B1, W2, B2, X)\n",
    "    dW1, dB1, dW2, dB2 = backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y)\n",
    "    W1, B1, W2, B2 = update_parameters(W1, B1, W2, B2, dW1, dB1, dW2, dB2, alpha)\n",
    "\n",
    "    if (i%20)==0:\n",
    "      print(\"Iteration number: \", i)\n",
    "      print(\"Accuracy = \", get_accuracy(get_predictions(A2), Y))\n",
    "  return W1, B1, W2, B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9404aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  0\n",
      "Accuracy =  0.09547619047619048\n",
      "Iteration number:  20\n",
      "Accuracy =  0.3036309523809524\n",
      "Iteration number:  40\n",
      "Accuracy =  0.4079761904761905\n",
      "Iteration number:  60\n",
      "Accuracy =  0.4825297619047619\n",
      "Iteration number:  80\n",
      "Accuracy =  0.5496130952380952\n",
      "Iteration number:  100\n",
      "Accuracy =  0.5955654761904762\n",
      "Iteration number:  120\n",
      "Accuracy =  0.6373809523809524\n",
      "Iteration number:  140\n",
      "Accuracy =  0.6715178571428572\n",
      "Iteration number:  160\n",
      "Accuracy =  0.6997916666666667\n",
      "Iteration number:  180\n",
      "Accuracy =  0.7225892857142857\n",
      "Iteration number:  200\n",
      "Accuracy =  0.7402380952380953\n",
      "Iteration number:  220\n",
      "Accuracy =  0.7549702380952381\n",
      "Iteration number:  240\n",
      "Accuracy =  0.7682440476190476\n",
      "Iteration number:  260\n",
      "Accuracy =  0.7791964285714286\n",
      "Iteration number:  280\n",
      "Accuracy =  0.7886904761904762\n",
      "Iteration number:  300\n",
      "Accuracy =  0.7962797619047619\n",
      "Iteration number:  320\n",
      "Accuracy =  0.8032738095238096\n",
      "Iteration number:  340\n",
      "Accuracy =  0.8097916666666667\n",
      "Iteration number:  360\n",
      "Accuracy =  0.8162202380952381\n",
      "Iteration number:  380\n",
      "Accuracy =  0.820952380952381\n",
      "Iteration number:  400\n",
      "Accuracy =  0.8257142857142857\n",
      "Iteration number:  420\n",
      "Accuracy =  0.8291369047619047\n",
      "Iteration number:  440\n",
      "Accuracy =  0.8326488095238095\n",
      "Iteration number:  460\n",
      "Accuracy =  0.8361309523809524\n",
      "Iteration number:  480\n",
      "Accuracy =  0.8388988095238096\n",
      "Iteration number:  500\n",
      "Accuracy =  0.8419345238095238\n",
      "Iteration number:  520\n",
      "Accuracy =  0.8449404761904762\n",
      "Iteration number:  540\n",
      "Accuracy =  0.8471428571428572\n",
      "Iteration number:  560\n",
      "Accuracy =  0.8489285714285715\n",
      "Iteration number:  580\n",
      "Accuracy =  0.8505654761904762\n",
      "Iteration number:  600\n",
      "Accuracy =  0.8525297619047619\n",
      "Iteration number:  620\n",
      "Accuracy =  0.8545238095238096\n",
      "Iteration number:  640\n",
      "Accuracy =  0.8561011904761905\n",
      "Iteration number:  660\n",
      "Accuracy =  0.8575595238095238\n",
      "Iteration number:  680\n",
      "Accuracy =  0.8590178571428572\n",
      "Iteration number:  700\n",
      "Accuracy =  0.8603869047619047\n",
      "Iteration number:  720\n",
      "Accuracy =  0.8615773809523809\n",
      "Iteration number:  740\n",
      "Accuracy =  0.8629761904761905\n",
      "Iteration number:  760\n",
      "Accuracy =  0.8643154761904762\n",
      "Iteration number:  780\n",
      "Accuracy =  0.8657440476190477\n",
      "Iteration number:  800\n",
      "Accuracy =  0.8672321428571429\n",
      "Iteration number:  820\n",
      "Accuracy =  0.8683333333333333\n",
      "Iteration number:  840\n",
      "Accuracy =  0.8692559523809524\n",
      "Iteration number:  860\n",
      "Accuracy =  0.8703571428571428\n",
      "Iteration number:  880\n",
      "Accuracy =  0.8715773809523809\n",
      "Iteration number:  900\n",
      "Accuracy =  0.872529761904762\n",
      "Iteration number:  920\n",
      "Accuracy =  0.8736309523809523\n",
      "Iteration number:  940\n",
      "Accuracy =  0.8743452380952381\n",
      "Iteration number:  960\n",
      "Accuracy =  0.8751785714285715\n",
      "Iteration number:  980\n",
      "Accuracy =  0.8757440476190477\n"
     ]
    }
   ],
   "source": [
    "W1, B1, W2, B2 = gradient_descent(X_train, Y_train, 0.1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a05d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label:  [9]\n",
      "Actual label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM/ElEQVR4nO3dYaxU9ZnH8d9v3TYxUg0IuhcLUokvVjbBrgRNaDZsSIn6BprgWl5s3ES9vIBNb6zZEnxR35hod91mE5PGS6rQDWutabW+wBVCmljfNFwNIhfSqjdsS7lybUmEJsaqPPviHpor3vnPZc7MnMHn+0luZuY8c855csKPc2bOmfN3RAjA599fNd0AgP4g7EAShB1IgrADSRB2IIm/7ufKbPPVP9BjEeHZptfas9u+3favbb9te3udZQHoLXd6nt32ZZJ+I+nrkk5IOihpc0QcLczDnh3osV7s2VdLejsiJiLiz5J+LGlDjeUB6KE6Yb9O0u9mvD5RTfsU28O2x2yP1VgXgJrqfEE326HCZw7TI2JU0qjEYTzQpDp79hOSlsx4/WVJJ+u1A6BX6oT9oKQbbX/F9hclfVPSi91pC0C3dXwYHxEf294m6WVJl0l6KiLGu9YZgK7q+NRbRyvjMzvQcz25qAbApYOwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kETH47NLku3jks5K+kTSxxGxqhtNAei+WmGv/GNE/KELywHQQxzGA0nUDXtI2mf7NdvDs73B9rDtMdtjNdcFoAZHROcz24sj4qTtayTtl/SvEfFK4f2drwzAnESEZ5tea88eESerxylJz0taXWd5AHqn47DbvsL2l84/l7Re0pFuNQagu+p8G3+tpOdtn1/O/0TE/3alK3TNmjVrivVNmzYV6yMjI8X6uXPnivXx8fGWtXXr1hXnfe+994p1XJyOwx4RE5JWdrEXAD3EqTcgCcIOJEHYgSQIO5AEYQeSqHUF3UWvjCvoOrJs2bJi/f77729Zu++++4rzXn311cV6dWq1pTr/fp588slifevWrR0vO7OeXEEH4NJB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ59ACxfvrxY37dvX7F+/fXXd7zuHTt2FOt79+4t1m+99dZivXQufWpqqjjv4sWLi3XMjvPsQHKEHUiCsANJEHYgCcIOJEHYgSQIO5BENwZ2RBtLliwp1vfv31+sL126tFg/fvx4y9pDDz1UnPe5554r1tvdKrrdb+0xONizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASnGfvg1tuuaVYb3ce/cMPPyzW169f37I2MTFRnLeudvelx+Bou2e3/ZTtKdtHZkxbYHu/7beqx/m9bRNAXXM5jN8l6fYLpm2XdCAibpR0oHoNYIC1DXtEvCLp9AWTN0jaXT3fLWljd9sC0G2dfma/NiImJSkiJm1f0+qNtoclDXe4HgBd0vMv6CJiVNKoxA0ngSZ1eurtlO0hSaoey7cJBdC4TsP+oqR7quf3SPp5d9oB0CttD+NtPyNpraSFtk9I+q6kRyX9xPa9kn4r6a5eNnmpu+uueptnz549xXqvz6Xj86Ft2CNic4vSui73AqCHuFwWSIKwA0kQdiAJwg4kQdiBJPiJax989NFHteZ/5JFHutTJxdu0aVOxXvp5LQYLe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSMIR/bt5TNY71dx2223F+quvvlqsj4yMFOtPPPHExbY0Z4cPHy7Wb7rppo6XPTVVvufJ4sWLO152ZhHh2aazZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJPg9+yXg8ccfL9bfeeedlrWXXnqpOO8NN9xQrK9YsaJY7+d1GqiHPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59j549913i/V258LvuOOOYn3Xrl0ta2fPni3Oe+WVVxbr7WzZsqVYf/DBB1vWrrrqqlrrxsVpu2e3/ZTtKdtHZkx72PbvbR+q/u7sbZsA6prLYfwuSbfPMv37EXFz9be3u20B6La2YY+IVySd7kMvAHqozhd022wfrg7z57d6k+1h22O2x2qsC0BNnYb9B5KWS7pZ0qSklr/UiIjRiFgVEas6XBeALugo7BFxKiI+iYhzknZKWt3dtgB0W0dhtz004+U3JB1p9V4Ag6HtfeNtPyNpraSFkk5J+m71+mZJIem4pC0RMdl2ZUnvG1/X6OhosX733Xe3rM2bN68475kzZ4r1Bx54oFh/+umni/XSfecXLVpUnHdoaKhYx+xa3Te+7UU1EbF5lsk/rN0RgL7iclkgCcIOJEHYgSQIO5AEYQeSYMjmz4GVK1e2rC1durQ478TERLE+Pj5erC9YsKBYP3jwYMva5ZdfXpyXIZs7w5DNQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AE59lRy7p164r1l19+uWVtamqqOC/n2TvDeXYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Iou0orkDJ+++/X6x/8MEHfeoE7bTds9teYvsXto/ZHrf9rWr6Atv7bb9VPc7vfbsAOjWXw/iPJX07Iv5W0m2Sttq+SdJ2SQci4kZJB6rXAAZU27BHxGREvF49PyvpmKTrJG2QtLt6225JG3vUI4AuuKjP7LaXSfqqpF9JujYiJqXp/xBsX9NinmFJwzX7BFDTnMNue56kn0oaiYgz9qz3tPuMiBiVNFotgxtOAg2Z06k321/QdND3RMTPqsmnbA9V9SFJ5VuFAmhU21tJe3oXvlvS6YgYmTH93yX9MSIetb1d0oKI+Lc2y2LPnswbb7zRsrZo0aLivNxKujOtbiU9l8P4NZL+WdKbtg9V03ZIelTST2zfK+m3ku7qQp8AeqRt2CPiVUmtPqCXRwgAMDC4XBZIgrADSRB2IAnCDiRB2IEk+IkrGrNw4cJifePGjcX6Cy+80L1mEmDPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ4dPXXgwIGWtRUrVhTn3bZtW7He7vfwO3fuLNazYc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwnh09dfTo0Y7nXbt2bbE+OTlZrHOe/dPYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEm3Ps9teIulHkv5G0jlJoxHxX7YflnS/pPeqt+6IiL29ahSXpmeffbZlbeXKlcV52903/rHHHuukpbTmclHNx5K+HRGv2/6SpNds769q34+I/+hdewC6ZS7js09Kmqyen7V9TNJ1vW4MQHdd1Gd228skfVXSr6pJ22wftv2U7fkt5hm2PWZ7rF6rAOqYc9htz5P0U0kjEXFG0g8kLZd0s6b3/I/PNl9EjEbEqohYVb9dAJ2aU9htf0HTQd8TET+TpIg4FRGfRMQ5STslre5dmwDqaht225b0Q0nHIuI/Z0wfmvG2b0g60v32AHSLI6L8Bvtrkn4p6U1Nn3qTpB2SNmv6ED4kHZe0pfoyr7Ss8soA1BYRnm1627B3E2EHeq9V2LmCDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kES/h2z+g6T/m/F6YTVtEA1qb4Pal0Rvnepmb9e3KvT19+yfWbk9Nqj3phvU3ga1L4neOtWv3jiMB5Ig7EASTYd9tOH1lwxqb4Pal0RvnepLb41+ZgfQP03v2QH0CWEHkmgk7LZvt/1r22/b3t5ED63YPm77TduHmh6frhpDb8r2kRnTFtjeb/ut6nHWMfYa6u1h27+vtt0h23c21NsS27+wfcz2uO1vVdMb3XaFvvqy3fr+md32ZZJ+I+nrkk5IOihpc0Qc7WsjLdg+LmlVRDR+AYbtf5D0J0k/ioi/q6Z9T9LpiHi0+o9yfkR8Z0B6e1jSn5oexrsarWho5jDjkjZK+hc1uO0Kff2T+rDdmtizr5b0dkRMRMSfJf1Y0oYG+hh4EfGKpNMXTN4gaXf1fLem/7H0XYveBkJETEbE69Xzs5LODzPe6LYr9NUXTYT9Okm/m/H6hAZrvPeQtM/2a7aHm25mFteeH2arerym4X4u1HYY7366YJjxgdl2nQx/XlcTYZ9taJpBOv+3JiL+XtIdkrZWh6uYmzkN490vswwzPhA6Hf68ribCfkLSkhmvvyzpZAN9zCoiTlaPU5Ke1+ANRX3q/Ai61eNUw/38xSAN4z3bMOMagG3X5PDnTYT9oKQbbX/F9hclfVPSiw308Rm2r6i+OJHtKySt1+ANRf2ipHuq5/dI+nmDvXzKoAzj3WqYcTW87Rof/jwi+v4n6U5NfyP/jqSHmuihRV83SHqj+htvujdJz2j6sO4jTR8R3SvpakkHJL1VPS4YoN7+W9NDex/WdLCGGurta5r+aHhY0qHq786mt12hr75sNy6XBZLgCjogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSOL/ASDoEHSfqgdLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_index = 560\n",
    "Z1val, A1val, Z2val, A2val = forward_propagation(W1, B1, W2, B2, X_val[:, val_index, None])\n",
    "print(\"Predicted label: \", get_predictions(A2val))\n",
    "print(\"Actual label: \", Y_val[val_index])\n",
    "\n",
    "image_array = X_val[:,val_index].reshape(28,28)\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c908219e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  0.8764285714285714\n"
     ]
    }
   ],
   "source": [
    "Z1val, A1val, Z2val, A2val = forward_propagation(W1, B1, W2, B2, X_val)\n",
    "val_acc = get_accuracy(get_predictions(A2val), Y_val)\n",
    "print(\"Validation accuracy = \", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75048e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
